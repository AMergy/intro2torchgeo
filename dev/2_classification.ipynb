{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anne/miniconda3/envs/torchgeo/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import numpy as np\n",
    "from typing import Tuple\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchgeo.datasets import NAIP, ChesapeakeDE\n",
    "from torchgeo.datasets.utils import download_url, stack_samples\n",
    "from torchgeo.models import resnet50 as resnet50_torchgeo\n",
    "from torchgeo.samplers import RandomGeoSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchgeo.datasets as dg_datasets\n",
    "import torchgeo.models as dg_models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the splits for the training. For more information about this cell, refer to `1_data_exploration.ipynb` tutorial. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = tempfile.gettempdir()\n",
    "naip_url = (\n",
    "    \"https://naipeuwest.blob.core.windows.net/naip/v002/de/2018/de_060cm_2018/38075/\"\n",
    ")\n",
    "TILES = [\n",
    "    \"m_3807511_ne_18_060_20181104.tif\",\n",
    "    \"m_3807511_se_18_060_20181104.tif\",\n",
    "    \"m_3807512_nw_18_060_20180815.tif\"]\n",
    "cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /tmp/naip_train/m_3807511_ne_18_060_20181104.tif\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "naip_root = os.path.join(data_root, \"naip_train\")\n",
    "download_url(naip_url + TILES[0], naip_root)\n",
    "\n",
    "chesapeake_root = os.path.join(data_root, \"chesapeake_train\")\n",
    "chesapeake = ChesapeakeDE(chesapeake_root, download=True)\n",
    "\n",
    "train_chesapeake = ChesapeakeDE(chesapeake_root, cache=cache)\n",
    "train_naip = NAIP(naip_root, crs=chesapeake.crs, \n",
    "                  res=chesapeake.res, cache=cache)\n",
    "\n",
    "train_dataset = train_chesapeake & train_naip\n",
    "# train_sampler = GridGeoSampler(train_dataset, size=1000, stride=500)\n",
    "train_sampler = RandomGeoSampler(train_dataset, size=256, length=10000)\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=8, sampler=train_sampler, \n",
    "    collate_fn=stack_samples, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using downloaded and verified file: /tmp/naip_val/m_3807511_se_18_060_20181104.tif\n"
     ]
    }
   ],
   "source": [
    "# Validation set\n",
    "naip_root = os.path.join(data_root, \"naip_val\")\n",
    "download_url(naip_url + TILES[1], naip_root)\n",
    "\n",
    "# chesapeake_root = os.path.join(data_root, \"chesapeake_val\")\n",
    "# chesapeake = ChesapeakeDE(chesapeake_root, download=True)\n",
    "\n",
    "val_chesapeake = ChesapeakeDE(chesapeake_root, cache=cache)\n",
    "val_naip = NAIP(naip_root, crs=chesapeake.crs, \n",
    "                  res=chesapeake.res, cache=cache)\n",
    "\n",
    "val_dataset = val_chesapeake & val_naip\n",
    "# val_sampler = GridGeoSampler(val_dataset, size=1000, stride=500)\n",
    "val_sampler = RandomGeoSampler(val_dataset, size=256, length=10000)\n",
    "\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=8, sampler=val_sampler, \n",
    "    collate_fn=stack_samples, shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 50.,  47.,  35.,  ..., 191., 191., 189.],\n",
       "          [ 51.,  37.,  46.,  ..., 181., 181., 189.],\n",
       "          [ 50.,  58.,  71.,  ..., 186., 187., 183.],\n",
       "          ...,\n",
       "          [183., 180., 179.,  ..., 186., 187., 190.],\n",
       "          [182., 186., 180.,  ..., 190., 183., 189.],\n",
       "          [177., 187., 181.,  ..., 187., 184., 189.]],\n",
       "\n",
       "         [[ 54.,  43.,  42.,  ..., 182., 187., 178.],\n",
       "          [ 54.,  43.,  44.,  ..., 174., 175., 178.],\n",
       "          [ 46.,  57.,  61.,  ..., 181., 176., 176.],\n",
       "          ...,\n",
       "          [181., 166., 166.,  ..., 180., 181., 173.],\n",
       "          [172., 173., 171.,  ..., 181., 180., 178.],\n",
       "          [172., 173., 171.,  ..., 177., 179., 178.]],\n",
       "\n",
       "         [[ 51.,  43.,  42.,  ..., 158., 158., 150.],\n",
       "          [ 50.,  50.,  53.,  ..., 152., 147., 150.],\n",
       "          [ 45.,  53.,  63.,  ..., 155., 151., 142.],\n",
       "          ...,\n",
       "          [155., 142., 140.,  ..., 158., 153., 153.],\n",
       "          [148., 151., 145.,  ..., 156., 154., 151.],\n",
       "          [150., 147., 148.,  ..., 151., 156., 150.]],\n",
       "\n",
       "         [[ 48.,  37.,  44.,  ..., 147., 149., 151.],\n",
       "          [ 36.,  40.,  42.,  ..., 144., 151., 151.],\n",
       "          [ 44.,  67.,  76.,  ..., 148., 140., 146.],\n",
       "          ...,\n",
       "          [139., 129., 130.,  ..., 144., 148., 148.],\n",
       "          [138., 143., 136.,  ..., 142., 151., 143.],\n",
       "          [137., 144., 141.,  ..., 142., 148., 145.]]],\n",
       "\n",
       "\n",
       "        [[[156., 133., 153.,  ..., 175., 174., 189.],\n",
       "          [155., 141., 137.,  ...,  55., 151., 162.],\n",
       "          [162., 148., 134.,  ...,  38.,  33.,  54.],\n",
       "          ...,\n",
       "          [ 90.,  99.,  44.,  ...,  73.,  82., 184.],\n",
       "          [ 83.,  75.,  85.,  ...,  66.,  75.,  92.],\n",
       "          [144.,  97., 156.,  ...,  62., 107.,  58.]],\n",
       "\n",
       "         [[141., 134., 138.,  ..., 176., 169., 186.],\n",
       "          [146., 137., 126.,  ...,  59., 125., 134.],\n",
       "          [147., 137., 128.,  ...,  38.,  35.,  46.],\n",
       "          ...,\n",
       "          [100.,  95.,  56.,  ...,  75.,  72., 152.],\n",
       "          [ 85.,  60.,  95.,  ...,  60.,  68.,  87.],\n",
       "          [118.,  96., 140.,  ...,  67., 103.,  61.]],\n",
       "\n",
       "         [[114.,  98., 104.,  ..., 142., 163., 182.],\n",
       "          [112., 100., 106.,  ...,  72., 116., 127.],\n",
       "          [115., 105., 106.,  ...,  44.,  45.,  71.],\n",
       "          ...,\n",
       "          [ 75.,  72.,  50.,  ...,  54.,  75., 136.],\n",
       "          [ 69.,  53.,  82.,  ...,  62.,  68.,  77.],\n",
       "          [ 97.,  82., 105.,  ...,  59.,  93.,  71.]],\n",
       "\n",
       "         [[161., 157., 152.,  ..., 137., 149., 139.],\n",
       "          [164., 150., 147.,  ...,  25.,  89., 130.],\n",
       "          [171., 151., 147.,  ...,  16.,  24.,  22.],\n",
       "          ...,\n",
       "          [158., 148., 105.,  ..., 109., 157., 205.],\n",
       "          [117., 107., 126.,  ...,  82.,  83., 133.],\n",
       "          [136., 131., 152.,  ...,  78., 118.,  99.]]],\n",
       "\n",
       "\n",
       "        [[[117., 119., 122.,  ...,  54., 100., 151.],\n",
       "          [115., 137., 114.,  ...,  48., 136., 152.],\n",
       "          [126., 135., 125.,  ...,  52.,  76., 129.],\n",
       "          ...,\n",
       "          [135., 119., 126.,  ..., 117., 130., 143.],\n",
       "          [159., 124., 135.,  ..., 129., 115., 109.],\n",
       "          [135., 132., 122.,  ...,  99., 111., 122.]],\n",
       "\n",
       "         [[122., 121., 120.,  ...,  41., 110., 128.],\n",
       "          [120., 121., 121.,  ...,  47., 112., 146.],\n",
       "          [127., 127., 108.,  ...,  48.,  78., 122.],\n",
       "          ...,\n",
       "          [132., 127., 117.,  ..., 129., 136., 142.],\n",
       "          [135., 122., 129.,  ..., 147., 138., 130.],\n",
       "          [135., 104., 109.,  ..., 120., 116., 142.]],\n",
       "\n",
       "         [[ 90.,  79.,  82.,  ...,  46., 100., 110.],\n",
       "          [ 79.,  84.,  91.,  ...,  52., 105., 117.],\n",
       "          [ 98.,  95.,  76.,  ...,  51.,  91., 107.],\n",
       "          ...,\n",
       "          [103.,  85.,  93.,  ...,  96.,  94.,  93.],\n",
       "          [102.,  88., 101.,  ...,  92.,  82.,  85.],\n",
       "          [109.,  78.,  82.,  ...,  78.,  79.,  87.]],\n",
       "\n",
       "         [[130., 119., 129.,  ...,  48., 100., 139.],\n",
       "          [134., 125., 135.,  ...,  50., 109., 152.],\n",
       "          [141., 115., 128.,  ...,  71.,  92., 131.],\n",
       "          ...,\n",
       "          [123., 108., 102.,  ..., 151., 156., 154.],\n",
       "          [135., 119., 123.,  ..., 152., 148., 147.],\n",
       "          [130., 115., 110.,  ..., 136., 134., 150.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[  0.,   0.,   0.,  ...,  92.,  86.,  79.],\n",
       "          [  0.,   0.,   0.,  ...,  81.,  91.,  96.],\n",
       "          [  0.,   0.,   0.,  ...,  79.,  87.,  91.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,  58.,  88.,  92.],\n",
       "          [  0.,   0.,   0.,  ...,  51.,  71., 111.],\n",
       "          [  0.,   0.,   0.,  ..., 143., 153., 130.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ..., 146., 130., 129.],\n",
       "          [  0.,   0.,   0.,  ..., 127., 145., 147.],\n",
       "          [  0.,   0.,   0.,  ..., 139., 144., 137.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,  51.,  71.,  92.],\n",
       "          [  0.,   0.,   0.,  ...,  69.,  51., 105.],\n",
       "          [  0.,   0.,   0.,  ..., 120., 120., 114.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ...,  78.,  82.,  79.],\n",
       "          [  0.,   0.,   0.,  ...,  77.,  79.,  85.],\n",
       "          [  0.,   0.,   0.,  ...,  83.,  82.,  79.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ...,  50.,  52.,  62.],\n",
       "          [  0.,   0.,   0.,  ...,  54.,  55.,  65.],\n",
       "          [  0.,   0.,   0.,  ...,  79.,  81.,  61.]],\n",
       "\n",
       "         [[  0.,   0.,   0.,  ..., 235., 227., 209.],\n",
       "          [  0.,   0.,   0.,  ..., 223., 238., 208.],\n",
       "          [  0.,   0.,   0.,  ..., 237., 225., 209.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ..., 121., 139., 134.],\n",
       "          [  0.,   0.,   0.,  ..., 126., 114., 157.],\n",
       "          [  0.,   0.,   0.,  ..., 183., 196., 173.]]],\n",
       "\n",
       "\n",
       "        [[[171., 180., 177.,  ..., 177., 171., 180.],\n",
       "          [171., 180., 179.,  ..., 170., 173., 177.],\n",
       "          [174., 179., 177.,  ..., 168., 174., 169.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ..., 183., 182., 186.],\n",
       "          [  0.,   0.,   0.,  ..., 180., 186., 184.],\n",
       "          [  0.,   0.,   0.,  ..., 174., 183., 187.]],\n",
       "\n",
       "         [[164., 171., 172.,  ..., 165., 166., 171.],\n",
       "          [170., 174., 171.,  ..., 166., 167., 170.],\n",
       "          [169., 169., 175.,  ..., 160., 170., 167.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ..., 178., 179., 180.],\n",
       "          [  0.,   0.,   0.,  ..., 177., 177., 180.],\n",
       "          [  0.,   0.,   0.,  ..., 171., 177., 178.]],\n",
       "\n",
       "         [[133., 142., 144.,  ..., 135., 141., 140.],\n",
       "          [139., 139., 149.,  ..., 132., 134., 141.],\n",
       "          [138., 143., 137.,  ..., 134., 140., 136.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ..., 150., 148., 157.],\n",
       "          [  0.,   0.,   0.,  ..., 147., 151., 147.],\n",
       "          [  0.,   0.,   0.,  ..., 141., 155., 154.]],\n",
       "\n",
       "         [[135., 140., 145.,  ..., 138., 135., 139.],\n",
       "          [136., 142., 139.,  ..., 133., 139., 136.],\n",
       "          [141., 140., 139.,  ..., 135., 140., 136.],\n",
       "          ...,\n",
       "          [  0.,   0.,   0.,  ..., 140., 146., 149.],\n",
       "          [  0.,   0.,   0.,  ..., 142., 143., 145.],\n",
       "          [  0.,   0.,   0.,  ..., 143., 145., 145.]]],\n",
       "\n",
       "\n",
       "        [[[185., 175., 183.,  ...,  47., 137.,  42.],\n",
       "          [184., 184., 184.,  ...,  73.,  50.,  59.],\n",
       "          [196., 197., 191.,  ..., 102.,  64.,  54.],\n",
       "          ...,\n",
       "          [ 66.,  35.,  38.,  ...,  51., 100., 101.],\n",
       "          [ 82.,  58.,  54.,  ...,  34.,  87., 111.],\n",
       "          [ 53.,  73.,  44.,  ...,  44.,  27.,  64.]],\n",
       "\n",
       "         [[162., 157., 163.,  ...,  53., 123.,  47.],\n",
       "          [178., 171., 169.,  ...,  77.,  60.,  80.],\n",
       "          [186., 188., 177.,  ...,  65.,  47.,  51.],\n",
       "          ...,\n",
       "          [ 79.,  39.,  46.,  ...,  59., 104., 110.],\n",
       "          [ 57.,  48.,  45.,  ...,  40.,  69.,  99.],\n",
       "          [ 53.,  67.,  44.,  ...,  55.,  40.,  66.]],\n",
       "\n",
       "         [[139., 130., 137.,  ...,  46.,  77.,  55.],\n",
       "          [150., 144., 149.,  ...,  50.,  68.,  54.],\n",
       "          [164., 164., 157.,  ...,  60.,  56.,  59.],\n",
       "          ...,\n",
       "          [ 66.,  53.,  46.,  ...,  53.,  86., 100.],\n",
       "          [ 50.,  58.,  55.,  ...,  45.,  65.,  96.],\n",
       "          [ 53.,  61.,  57.,  ...,  59.,  50.,  63.]],\n",
       "\n",
       "         [[155., 143., 142.,  ...,  72., 150.,  63.],\n",
       "          [151., 154., 145.,  ..., 100., 121.,  76.],\n",
       "          [164., 163., 156.,  ..., 103.,  89.,  62.],\n",
       "          ...,\n",
       "          [126.,  36.,  70.,  ..., 104., 135., 131.],\n",
       "          [101.,  53.,  39.,  ...,  63.,  98., 131.],\n",
       "          [ 66.,  69.,  51.,  ...,  44.,  54.,  64.]]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(val_dataloader))[\"image\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_epochs = 10\n",
    "batch_size = 8\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchgeo.models import FarSeg\n",
    "\n",
    "# Load the pre-trained ResNet50 model\n",
    "# Modify the last layer; there are 12 classes + 0 standing for no_data\n",
    "model = FarSeg(backbone='resnet50', classes=13, backbone_pretrained=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code below, we first freeze all the layers except the first and last by setting `requires_grad` to False. Then, we modify the first layer to accept a 4-band image. Finally, we define the loss function and optimizer to only update the parameters that have `requires_grad set to True`. This is achieved using `filter` to select only the trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze all layers except the first and last\n",
    "for name, param in model.named_parameters():\n",
    "    if not ('conv1' in name or 'fc' in name):\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify the first layer to accept a 4-band image\n",
    "model.backbone.conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=(3, 3), bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Re-train resnet 50 weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - Train Loss: 1.8597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [1:26:34<12:59:09, 5194.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 26963242.43%\n",
      "Epoch 1 - Train Loss: 1.6553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [2:55:03<11:41:34, 5261.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27833313.72%\n",
      "Epoch 2 - Train Loss: 1.6314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [4:21:49<10:10:53, 5236.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27014443.73%\n",
      "Epoch 3 - Train Loss: 1.5880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [5:47:45<8:40:27, 5204.55s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 26168970.60%\n",
      "Epoch 4 - Train Loss: 1.7663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [7:12:55<7:10:52, 5170.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27271754.02%\n",
      "Epoch 5 - Train Loss: 1.7553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [8:37:11<5:42:05, 5131.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 26465652.95%\n",
      "Epoch 6 - Train Loss: 1.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [10:01:31<4:15:25, 5108.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 26647050.64%\n",
      "Epoch 7 - Train Loss: 1.6379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [11:25:11<2:49:20, 5080.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27517238.86%\n",
      "Epoch 8 - Train Loss: 1.6162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [12:48:50<1:24:20, 5061.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 27153539.46%\n",
      "Epoch 9 - Train Loss: 1.4646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [14:13:49<00:00, 5122.93s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 26814570.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Train the model\n",
    "for epoch in tqdm(range(10)):\n",
    "    model.train()\n",
    "    for i, sample in enumerate(train_dataloader):\n",
    "        inputs = sample[\"image\"].float()\n",
    "        labels = sample[\"mask\"]\n",
    "        # labels = torch.nn.functional.one_hot(sample[\"mask\"], num_classes=13).float()\n",
    "        # labels = labels.squeeze(dim=1).permute(0, 3, 1, 2)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs.view(outputs.shape[0],\n",
    "                                      outputs.shape[1],-1), \n",
    "                         labels.view(labels.shape[0],-1), \n",
    "                         )\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"Epoch {} - Train Loss: {:.4f}\".format(epoch, loss.item()))\n",
    "    path = os.path.join(\"res\",'try2-weights_{}_epochs.pt'.format(epoch))\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for sample in val_dataloader:\n",
    "            inputs = sample[\"image\"].float()\n",
    "            labels = sample[\"mask\"]\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(\"Validation Accuracy: {:.2f}%\".format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 1 hour to train 1 epoch (try 1: after 2/3 epochs)\n",
    "- train 10 epochs in: (try2: losses= 1.8597, 1.6553, 1.6314, 1.5880, 1.7663, 1.7553, 1.4781, 1.6379, 1.6162, )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Evaluate on test set\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for sample in test_dataloader:\n",
    "        inputs = sample[\"image\"].float()\n",
    "        labels = sample[\"mask\"]\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(\"Test Accuracy: {:.2f}%\".format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchgeo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f255346e1a93d72a837f80421b3cabc4fbc94636e4056adf99239953fe1f8a9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
